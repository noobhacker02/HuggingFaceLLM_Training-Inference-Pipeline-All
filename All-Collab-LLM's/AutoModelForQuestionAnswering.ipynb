{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We use Custom tokenization for the process as we convert the answers labels as well in fly by while tokenzing the questions and answers both"
      ],
      "metadata": {
        "id": "BiTy9_B3TUtM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "840f03acac89456e92a6a530c7b36148",
            "7a52f0ef77fa4a818c605891d4f457bd",
            "be61c3a2e8594fb5add4c4c24b2ef888",
            "a5e996f5908349bcba899be71d2c7b71",
            "37b4c67a9c3f413a9eeb5d224b962dfd",
            "b84a486fe98b452bae5da433ea530419",
            "30cc19a36a1b4607b23f1a8344d654c2",
            "6fe99700475444cd9cb500e88fe95e5b",
            "c6f35a7bebe24ed29bb2cc351faac672",
            "20f75aae48164b298a6b2701b3656476",
            "3eb6fb73a48e4822a6860a56a19e581e",
            "ae23aa87bdc544998a9d03be9be49d3d",
            "9ab0c4443b2e4ec4a5b5305d0b8656ab",
            "52445d52115b42699eb6be635a993591",
            "f8a71449535e485fb5c539cbf969b20f",
            "3fa9e5a6b14e4dbdbf488aea8030fd89",
            "a0d81a027e434ba8a54b9f6144de0d2c",
            "ab0b27ff9dfe470bb67f5417f8de0b12",
            "d55ef01571da4b4d8061b461e6f2716e",
            "f0bae0feead3465b8bfb475d008fe533",
            "0b01147ee18a4e878d5e930d3a181303",
            "012b020c86304ab3a1ae2923c7190d9d",
            "6a46bef8753640f2ab6a38586662a725",
            "d503d78d752143149ea8bccf2c5c0a20",
            "b50d95b83f2048dbbe2362bfa9a3c34f",
            "aa37a54448b74043b45d3f2d72a995b7",
            "650034cd62bb4dab9963fdb1146f3975",
            "0335642a4fb74c5aa627114ab37a2d9b",
            "d8a4d4db07784848a7618ccd7a79abc2",
            "952b3048f0be400cb0a1be6597e989ac",
            "30a91100be3542f2a69ebf49f3d60eef",
            "0489949b07474119b5998c42ccb393c2",
            "5b531cf2751a427a9712546f6e1f1952"
          ]
        },
        "id": "1KjmcWmS3_vs",
        "outputId": "f7408ad4-d681-45a3-d537-ff49591b18ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "840f03acac89456e92a6a530c7b36148"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae23aa87bdc544998a9d03be9be49d3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a46bef8753640f2ab6a38586662a725"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.6639722585678101,\n",
              " 'start': 90,\n",
              " 'end': 123,\n",
              " 'answer': 'natural language processing tasks'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "context = \"\"\"\n",
        "Transformers are a type of neural network architecture that has proven very effective\n",
        "in natural language processing tasks such as translation, summarization, and question answering.\n",
        "\"\"\"\n",
        "question = \"What are transformers effective in?\"\n",
        "results = qa_pipeline(question=question,context=context)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S2nk7L-94Wiw",
        "outputId": "bd1de18d-842b-4497-ab23-5294036487bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natural language processing tasks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question=['What are transformers effective in?','What is transformers']\n",
        "for q in question:\n",
        "  results = qa_pipeline(question=q,context=context)\n",
        "  print(f\"{q} is \\n {results['answer']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqYyO3Re5Lp5",
        "outputId": "d8d6f478-888d-4ed5-8f71-a5c3db700af4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are transformers effective in? is \n",
            " natural language processing tasks\n",
            "What is transformers is \n",
            " a type of neural network architecture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering"
      ],
      "metadata": {
        "id": "qJUFwz25565M"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased-distilled-squad\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "arrUiZz16cFl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"\n",
        "Transformers are a type of neural network architecture that has proven very effective\n",
        "in natural language processing tasks such as translation, summarization, and question answering.\n",
        "\"\"\"\n",
        "question = \"What are transformers effective in?\""
      ],
      "metadata": {
        "id": "qTDBg5g16eSX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1 = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n",
        "inputs2 = tokenizer(question, context, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "owHLMtFq6fzV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0RiVTF0_GnV",
        "outputId": "ad1f4c43-efa2-438c-cc02-646bf0511a94"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2054,  2024, 19081,  4621,  1999,  1029,   102, 19081,  2024,\n",
            "          1037,  2828,  1997, 15756,  2897,  4294,  2008,  2038, 10003,  2200,\n",
            "          4621,  1999,  3019,  2653,  6364,  8518,  2107,  2004,  5449,  1010,\n",
            "          7680,  7849,  3989,  1010,  1998,  3160, 10739,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abNELaKP_Oj2",
        "outputId": "9661d1c1-4449-4aa8-b534-41c118a748f2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2054,  2024, 19081,  4621,  1999,  1029,   102, 19081,  2024,\n",
            "          1037,  2828,  1997, 15756,  2897,  4294,  2008,  2038, 10003,  2200,\n",
            "          4621,  1999,  3019,  2653,  6364,  8518,  2107,  2004,  5449,  1010,\n",
            "          7680,  7849,  3989,  1010,  1998,  3160, 10739,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**inputs1)"
      ],
      "metadata": {
        "id": "X6J55Enl_Bqt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiJgnmjR_Fmz",
        "outputId": "c550373a-9b8c-4bb2-95f0-4dae47cccb20"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-3.6087, -1.3834, -4.4455, -5.1462, -5.5984, -5.7834, -6.7961, -4.1952,\n",
            "          0.3752, -2.3047,  0.1792, -1.0289, -3.2155,  0.4019, -2.8337, -3.6773,\n",
            "         -2.1924,  0.5996, -0.2567,  1.4552,  0.4001,  5.5784,  9.8733,  2.4162,\n",
            "          1.8921,  1.9476, -0.3090, -0.5154,  5.0634, -2.5000,  0.5546, -3.5805,\n",
            "         -3.7081, -4.5632, -1.7190,  3.8433, -0.6227, -2.0312, -4.1951]]), end_logits=tensor([[ 1.5828, -0.9164, -3.9716, -4.0415, -5.3970, -5.9616, -5.4072,  0.7678,\n",
            "         -0.9782, -4.7669, -4.5158, -4.1299, -4.3215, -2.9225, -2.1382, -0.1710,\n",
            "         -2.6407, -3.7716, -3.6661, -3.7771, -0.7429, -1.3387,  1.8818,  4.3482,\n",
            "          5.9046,  9.8188,  1.5871, -0.2823,  3.6626,  0.5503, -1.6100, -1.6441,\n",
            "          3.7606,  1.5100, -0.8276,  0.0966,  8.7454,  7.4695,  0.7681]]), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_scores, end_scores = outputs.start_logits, outputs.end_logits"
      ],
      "metadata": {
        "id": "Y8XHhfvoAvEd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_start = torch.argmax(start_scores)\n",
        "answer_end = torch.argmax(end_scores) + 1"
      ],
      "metadata": {
        "id": "-yGqTnwdZMKD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LenkQw3DZYR5",
        "outputId": "b2a3ef9d-819f-4770-c71d-9b86c2a6fe66"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2054,  2024, 19081,  4621,  1999,  1029,   102, 19081,  2024,\n",
              "          1037,  2828,  1997, 15756,  2897,  4294,  2008,  2038, 10003,  2200,\n",
              "          4621,  1999,  3019,  2653,  6364,  8518,  2107,  2004,  5449,  1010,\n",
              "          7680,  7849,  3989,  1010,  1998,  3160, 10739,  1012,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1[\"input_ids\"][0][1:9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNhYlzmJZd9L",
        "outputId": "712f3862-681c-4d47-c6c1-768f243e4742"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2054,  2024, 19081,  4621,  1999,  1029,   102, 19081])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tokenizer.convert_tokens_to_string(\n",
        "    tokenizer.convert_ids_to_tokens(inputs1[\"input_ids\"][0][answer_start:answer_end])\n",
        ")"
      ],
      "metadata": {
        "id": "PN9NvOypc39h"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UgrFcPXRdPxN",
        "outputId": "083ee8f3-2ebf-4a1e-a7cb-3d6ca2e95ca2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natural language processing tasks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ8CJ0KqgIXF",
        "outputId": "5ba85609-77f6-4622-be1a-5b5fa10e22a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyf3ahtbgvv4",
        "outputId": "3db363c5-d757-4ab8-bc0c-1a9c4b853c4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 1️⃣ Imports\n",
        "# ===========================\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "import torch\n",
        "import evaluate #using evaulate as we need to check the persentage of accuracy per tokens like respones accurasy\n"
      ],
      "metadata": {
        "id": "rFowkWNSf928"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2️⃣ Load dataset\n",
        "# ===========================\n",
        "dataset = load_dataset(\"squad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "293a6449bd824e4489ec7fb69d861813",
            "a205589977c34e79949086e2478ec745",
            "de1e89595bc143d09ee1b21dada55532",
            "1dc6c6f2bc304e7b91d221be1bdcbece",
            "7c39aaebef9b493483b5dff640ad6093",
            "35fa85c42de44b8a9f727ee05891aefb",
            "02d5f1a0623344599e4e4e6c9ed242c6",
            "b5a0e707281c45dc871462846b04ff64",
            "ff9e5f8e42a944748c9536be32394c48",
            "1fe475e33050459587a42e063ebc021a",
            "bf3fd8a744a4473bb84d2996fadafe3c",
            "3fd89c2432ea4e43a6c12d1bb1d955be",
            "2633732c173d4bbf9c937376190dacc8",
            "520688b81d784561a14ec0ece195158e",
            "15de2a4cbb274a3aa6ea26e150976caa",
            "d2fc07274f114616b11d5cd6f4708e1e",
            "7b4ce89ffc4d47e3954cbbe565531df1",
            "f85da218d86e4102bc925c1531fdb816",
            "7028d63b23604a8c89956761c6c0fb4e",
            "80f19c163fdb43af911bb9d09224585d",
            "6df0abf19ca344c1a475924215a85659",
            "a9b3f98eaaf844a29bf2b175adc1cd29",
            "8e70584ad3ea4671b5cc18464345067c",
            "82fd4af15b7d4db7bf03ea54139719ac",
            "520a1a1e4ed54cabb8e8be8a8033ea46",
            "4075065128b844d68246458857e459ab",
            "ce675f2ca638451e9602491edad71d0d",
            "218b54995b0f425abdb4464bc1fce517",
            "2a0359e2d10d4b55ab823c4e3383348d",
            "1c7fa3bf91474ab08ac0701b4a0f2d35",
            "efa4d540d4934051b4f73cf04e29097d",
            "3d8969ff076e4385ad12b95fd7039a78",
            "d80a7a9484a046f8bd2da00ffaa78d1b",
            "232aed7f805a4211b3ae4fb1478d6b90",
            "fdf82f326abb4660a770adcd808113d0",
            "5eb7364335904c8082acfeb30ef17e70",
            "de8ad29b157d470b9a44873e79effa7d",
            "409caf5cbccc423c9623679b451b3604",
            "baf0d1e8ec8e47af97faf8d1a17b4157",
            "4a939534258b4069b23e7e854bcc5f0d",
            "9b05cc25477243c794cb6ebf3049f5ed",
            "2ee0aa05cd584c68a77f6a57833eb9fc",
            "95877f4f6401441c95701465679bb80f",
            "979a25c91eda4f7ab992b4e9c0b81ed3",
            "c69b5af323a44c46ae210c85f9650bfc",
            "d8331908234a4093a599f4aad142baa4",
            "5c2aa5a1e6bb4f1b98de73ac2f4c93f7",
            "97d9b41cacd94cefa34934a9b2041a8d",
            "b7153b27eee2456d89e50db7618f562b",
            "fbcfc7a90b4b4a889a5009188489229c",
            "d9e5f82051a44fa380b21dc226a54972",
            "61987acfc860420da73c910b410ac311",
            "91305ec0120b469fa2e157e455587b60",
            "6869d08a233f4ec995cda995ce7c46b8",
            "ef32dd6d67fb4aa7b33f14784344b512"
          ]
        },
        "id": "BGsgiw0bgAQt",
        "outputId": "3f80fb50-fcdd-4dcf-e5c5-3801a153eaf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "293a6449bd824e4489ec7fb69d861813"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fd89c2432ea4e43a6c12d1bb1d955be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/validation-00000-of-00001.par(…):   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e70584ad3ea4671b5cc18464345067c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "232aed7f805a4211b3ae4fb1478d6b90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c69b5af323a44c46ae210c85f9650bfc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 3️⃣ Load tokenizer & model\n",
        "# ===========================\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "4427975119b7448aadf0e9b8a5acdbca",
            "93e1fb5bace54bc889e86d5c3ded83dc",
            "bc16976363db421390a423a1e97a658a",
            "e8c3acaa8906432cb9b0f932276c0510",
            "3bcce9d8f1d34565977b0181bc8b7e59",
            "1e777e67d6a24d1abc104a77e6ae07cc",
            "1596cf1b7ec740cf86c4224fca9081b0",
            "4dd05debb56047a3b154d404dffd50ac",
            "a1404376e20f463fbb1143ff12ffda32",
            "e70452c930e94fa3a05d9306312ff664",
            "a642b7f540004de1b4c93a8b0760462b",
            "468713dd0b234cbda40b21c8b1a4d703",
            "7ca42418814c46a5978d470e7acd80a8",
            "d6f4be8adbb84cf6b4852ae1d6e242d0",
            "c1c157d5c4be471d97acc0bc1fe6c220",
            "d3ac3f26f338457ea974271342fac5f9",
            "e3a62fef4f8b47b7acd481fe05a06e66",
            "b18fdd45e4644ae9a5c3ac7f4de79556",
            "5c52d9b7e9234e3bb44464e3d4f41cf1",
            "e838d3c3f8d446e3937caff1d186c4a8",
            "d6654b18b69f4514961872a2326fe74e",
            "94fbf692a87149acb2448baf4d57a496",
            "9f431c5bfabf4ed1b744b18dd37b7724",
            "2eb35be63d2547238bfb222dc2d9e212",
            "c983ea0e45b04113a18b949d4616d725",
            "ff626cf5a3e14fc3ac636d91123d459f",
            "7868e3efe09b46c995beaa38d6335b42",
            "cbe9e83760f444fbbdf14f66a00475e7",
            "4373b5e2d48e4f4381e8971f3acd60dd",
            "19f77f05d7bd423c87d43ac9c71dea4f",
            "be7e8d52746d457eb57286064cffd0d9",
            "ad80ba4a8e8f4612b470b16d2438f53f",
            "c5a321566bc842fb8b8b31e32039cc77",
            "e8bd3d536efb42f99077ac3b80f6820d",
            "8673172f3fb1431b87cd03db7236fac2",
            "fb8ab778533e483792351308c58ccd43",
            "c2145d4fbe0a46779c7643beda6c375d",
            "499570650a444bb9ad41890dd900ff19",
            "4502b3b136c343f59d1a82076d949b2e",
            "2204d152d6f4420a8aebe0833a0de762",
            "572852473aa24554adbd50a294b95c3e",
            "7f25c302032a4040a2ee144d2a1b8c50",
            "aec1230ab14a42548bd78fbaf67a4b07",
            "02753637a63149a38380c38c41002b9a",
            "cc76c949e1c443979c84dc972e296a2a",
            "46ba39e2c7bd4f9bb060c0b42cd1ec2f",
            "fd8b6be21c76402f9f29904e0c4c1da5",
            "2972f21c13ed455bae8314b679fed008",
            "cf2c245218c84abab19c2c7b1059ee88",
            "949752ea0c0e4106890f2add23d35b9e",
            "71ba69ece88a4531a242d7b3ad8f0964",
            "82031f6650de4d29a2178273c37aec58",
            "6c18ee30714c42eb99f9575d0ecadf50",
            "b2571766378e4a83907558d56461d889",
            "e1c813502d0d46a3856a8ab8d45bf123"
          ]
        },
        "id": "qoBvTwRDgKrd",
        "outputId": "67614d1f-82b3-490e-b953-fa1c9e8c2da8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4427975119b7448aadf0e9b8a5acdbca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "468713dd0b234cbda40b21c8b1a4d703"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f431c5bfabf4ed1b744b18dd37b7724"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8bd3d536efb42f99077ac3b80f6820d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc76c949e1c443979c84dc972e296a2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 0 - Select subsets for training & validation\n",
        "# ===========================\n",
        "train_ds = dataset[\"train\"].shuffle(seed=69).select(range(2000)) # we did this in Classification as well seed is random picks and range is well range\n",
        "validation_ds = dataset['validation'].shuffle(seed=69).select(range(500))"
      ],
      "metadata": {
        "id": "mtR_e25YJL_Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #as training on gpu we need to specify that train on gpu\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNc_clB9S9x2",
        "outputId": "e64f73b6-5627-4ec0-bd04-54757519c6c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForQuestionAnswering(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 4️⃣ Preprocessing function (tokenize + labels)\n",
        "# ===========================\n",
        "def preprocess_function(examples):\n",
        "    # Tokenize context + question with overlap\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=384,\n",
        "        stride=128,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    #start of the token + label maker process from the dataset\n",
        "    # Lists to store start/end positions\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    # Map each chunk back to original example\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    for i, offsets in enumerate(tokenized_examples[\"offset_mapping\"]):\n",
        "        # Original example for this chunk\n",
        "        sample_idx = sample_mapping[i]\n",
        "        answer = examples[\"answers\"][sample_idx]\n",
        "\n",
        "        # If no answer, default to CLS token\n",
        "        if len(answer[\"answer_start\"]) == 0:\n",
        "            start_positions.append(tokenizer.cls_token_id)\n",
        "            end_positions.append(tokenizer.cls_token_id)\n",
        "            continue\n",
        "\n",
        "        answer_start_char = answer[\"answer_start\"][0]\n",
        "        answer_end_char = answer_start_char + len(answer[\"text\"][0])\n",
        "\n",
        "        # Find context token positions in this chunk\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        cls_index = tokenized_examples[\"input_ids\"][i].index(tokenizer.cls_token_id)\n",
        "\n",
        "        token_start_index = 0\n",
        "        while sequence_ids[token_start_index] != 1:\n",
        "            token_start_index += 1\n",
        "        token_end_index = len(tokenized_examples[\"input_ids\"][i]) - 1\n",
        "        while sequence_ids[token_end_index] != 1:\n",
        "            token_end_index -= 1\n",
        "\n",
        "        # If answer not fully inside chunk, label as CLS\n",
        "        if not (offsets[token_start_index][0] <= answer_start_char and offsets[token_end_index][1] >= answer_end_char):\n",
        "            start_positions.append(cls_index)\n",
        "            end_positions.append(cls_index)\n",
        "        else:\n",
        "            # Exact token start\n",
        "            while token_start_index < len(offsets) and offsets[token_start_index][0] <= answer_start_char:\n",
        "                token_start_index += 1\n",
        "            start_positions.append(token_start_index - 1)\n",
        "\n",
        "            # Exact token end\n",
        "            while token_end_index >= 0 and offsets[token_end_index][1] >= answer_end_char:\n",
        "                token_end_index -= 1\n",
        "            end_positions.append(token_end_index + 1)\n",
        "\n",
        "    tokenized_examples[\"start_positions\"] = start_positions\n",
        "    tokenized_examples[\"end_positions\"] = end_positions\n",
        "\n",
        "    # We don’t need offset mapping for model\n",
        "    tokenized_examples.pop(\"offset_mapping\")\n",
        "    return tokenized_examples"
      ],
      "metadata": {
        "id": "qPiR6_GHgOdW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSG4jpkIv7Gp",
        "outputId": "f5c677b8-24d6-4c6b-f815-0033437ea5e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "    num_rows: 87599\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bFrJxkSlHg7",
        "outputId": "729e3f6e-8c37-47ee-9d20-fd4107cbeb2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '5733be284776f41900661180',\n",
              " 'title': 'University_of_Notre_Dame',\n",
              " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'question': 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?',\n",
              " 'answers': {'text': ['the Main Building'], 'answer_start': [279]}}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 5️⃣ Apply preprocessing\n",
        "# ===========================\n",
        "\n",
        "#removing colomns to make it of same size we do this cuz of chunking\n",
        "tokenized_train_ds = train_ds.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")\n",
        "tokenized_validation_ds = validation_ds.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "25e11ddc4b7c4b76876d4215a3ea9400",
            "48a6e1a088164309b3f30e794451df68",
            "ceee12bc351149088af4c9729bf36a2e",
            "fb8c99eaf3d442d6ac2f424f8451d22d",
            "0c20579ae62e4f90a1eacede00fb5449",
            "5e5de3138713425ba0091e2b40a9a27f",
            "23b6e97b5ccf4beb9bef62b9acbed3a9",
            "0549d5f8dd8648ed8a1bc4a37de70f19",
            "29b36e8b7ab941edb5f7abe6957bbd18",
            "4bf7ceb45d504de48cb7993c28e8e5c7",
            "6f5b6cf46d48437c86ba54b1b15a58f1",
            "f2bd93dd95494dd78bd6e869c3982fa1",
            "da9b16e2ea964f568f29b94f6bb5ac27",
            "164722e4bb7343d9980471afb7deff0f",
            "1497e34bfb9f4a51932967b45bdc125a",
            "931ea3a3fd864eecb240a9d3cd303251",
            "ca8e9d858c4644a98df42540892ebf18",
            "78a3b3c7dd06451f86e8b15b631cadcb",
            "9767d862f08545eb9c4f35263629328e",
            "be5a3e2937524ec291357dd1f053fd54",
            "d9a191f2bdd5496cb7bd74b121fa6630",
            "4aca4dcc4c0440f891f45f1b785608ec"
          ]
        },
        "id": "UWEpSzTtk7B0",
        "outputId": "2a6cf1ae-ecec-41f9-d098-064156553819"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25e11ddc4b7c4b76876d4215a3ea9400"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2bd93dd95494dd78bd6e869c3982fa1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4dPTeZByJUH",
        "outputId": "3dac3435-8a6e-4dc7-911c-9a4cd2575f63"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
              "    num_rows: 2025\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_train_ds[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdhDxSAzy25T",
        "outputId": "cad96bd8-85c6-4726-fbd9-fabe21d1fdd5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 5815, 2062, 3787, 2000, 1037, 8038, 5856, 1011, 20904, 2050, 2052, 2031, 2054, 3466, 1029, 102, 1037, 8038, 5856, 1011, 20904, 2050, 9140, 3594, 13135, 3787, 2000, 6551, 3623, 5114, 1012, 2009, 2003, 2328, 2247, 1037, 2490, 8797, 2008, 2003, 4197, 2646, 1996, 4742, 1010, 1998, 2947, 5927, 2053, 10572, 4742, 1998, 2515, 2025, 9002, 2000, 1996, 13438, 1005, 1055, 3169, 1012, 1996, 2203, 3553, 2000, 1996, 3120, 2003, 3615, 2000, 2004, 1996, 2392, 1012, 2379, 1996, 4373, 2003, 1037, 2309, 3161, 5783, 1010, 4050, 1037, 2431, 1011, 4400, 16510, 9890, 2030, 6999, 16510, 9890, 1012, 13135, 3787, 2024, 5412, 1999, 2392, 1006, 5501, 1007, 1998, 2369, 1006, 8339, 5668, 1007, 1996, 3161, 5783, 2247, 1996, 8797, 1012, 1996, 8038, 5856, 2038, 1996, 16112, 3737, 2008, 2009, 4150, 6233, 20396, 1010, 1998, 2947, 2038, 3020, 5114, 1010, 2004, 1996, 2193, 1997, 3787, 7457, 1012, 2174, 1010, 2023, 2036, 3084, 2009, 6233, 7591, 2000, 3431, 1999, 6075, 1025, 2065, 1996, 4742, 6075, 3431, 1010, 2025, 2069, 2515, 1996, 3161, 5783, 4374, 2625, 2943, 3495, 1010, 2021, 2035, 1997, 1996, 13135, 3787, 5815, 2000, 2008, 4742, 2036, 9885, 2037, 6434, 2004, 2092, 1998, 2037, 7755, 2053, 2936, 3362, 1996, 3161, 5783, 1999, 1011, 4403, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'start_positions': 129, 'end_positions': 130}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_validation_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQkdsl7Z28uN",
        "outputId": "5e4ba3c1-074a-4220-ed81-ae78e2cb5ccd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
              "    num_rows: 512\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"squad\")\n",
        "def compute_metrics(p):\n",
        "    return metric.compute(predictions=p.predictions, references=p.label_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d353221465bf4c138de096d2069ad89a",
            "433834942d904ae39701e61875e5dac1",
            "fe2c5569d2dd4bad99d043550a3d94c6",
            "8a8c5e46bc604c7fae73b32c6df20d45",
            "297c117dfe1a4389be3e5019e9b21685",
            "0ae8dacf11834d2a930554a72f5527fd",
            "7a395ac8551b4e78befac815b73655b5",
            "4b826e40b65e4ef3856482fb2fd335cf",
            "12b3e4d4afbc428d877cdc278cf2be0c",
            "4a1cdd908a8d4fd7a9452365baeeff58",
            "fd81e4c5c4b345f497bc8d24f72b9f2e",
            "426d543c969c471faa01819ea2de9c77",
            "e6de62d655214fc1a81e8082e09e7182",
            "088b9ea49571449c8853208bf4f184cf",
            "3cd9555668be4605ad167a5fd951fd23",
            "0d9082e9db6e452b8607a233d239b546",
            "96d311d631004ca18c7dcf96f73c47fa",
            "3166bb4b2d9547cd88c65449a5b70f5c",
            "d749be0cbd294d0e947db72cb99abdfe",
            "ea017d4915e44f32bf8a2d81f56de83f",
            "d7e884c2979841cea48ed9f9483f7dda",
            "6643020396e6419ca3eef53fb3eeb628"
          ]
        },
        "id": "lgMyCOtGy6GU",
        "outputId": "8549f4fd-238b-43c3-ad70-edfcb812ab4e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d353221465bf4c138de096d2069ad89a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "426d543c969c471faa01819ea2de9c77"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./qa_model\",\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_ds,\n",
        "    eval_dataset=tokenized_validation_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK664Vcy120W",
        "outputId": "2c6031ad-621d-456c-c4e9-b936c4c451b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2513484893.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "trainer.train()\n",
        "\n",
        "# Save model\n",
        "trainer.save_model(\"./custom_qa_model\")\n",
        "tokenizer.save_pretrained(\"./custom_qa_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "gIABaMXL3EX1",
        "outputId": "71af1584-eff0-4cd1-b1d6-194109482c55"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 02:26, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./custom_qa_model/tokenizer_config.json',\n",
              " './custom_qa_model/special_tokens_map.json',\n",
              " './custom_qa_model/vocab.txt',\n",
              " './custom_qa_model/added_tokens.json',\n",
              " './custom_qa_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_code = ''"
      ],
      "metadata": {
        "id": "0SEdQzuE3VZw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "0e9e8e493e784dcc9585278f2d21bf48",
            "8025dd5c992147fda4159b115588f44c",
            "7493d4c14e894579bec49597d81173a5",
            "63fd1600ff1242bbafc81c83ff048784",
            "aeb8e37265dd4414b4f2f097a22e2426",
            "55f90527ccf444999a7dc3a1a13bec0f",
            "c550b819f012449aaabff08fdf837380",
            "7563d6927ff84ef89add5b8e134f6d21",
            "eb16aced6e804e4aaadebec5a1130453",
            "aa1fe42de4ba4714bdeed0f77619e59a",
            "269cc492749242d6add5ba0b3050a0bf",
            "a1a4d17598d54f3193fdca1fc37e514d",
            "de0dd9c4b2e147538086a2146d001bbc",
            "c5d6be5e79394cb7987f3d0f8b15cafc",
            "42f381021b1b46c79348b8da058e149f",
            "daf20b73b13b48f8a8a57b42a016fead",
            "32bcc3b30c834485bb52f10ca0c58ec9",
            "4ec0a16e1c2f430f85b9ca350b35b2b8",
            "5e1aeb59d6f748c0829db83a64e0a3bf",
            "6d657403b6eb489f845654652a30bb81"
          ]
        },
        "id": "IlyHRs04WOe9",
        "outputId": "dc9d55ba-7671-42e9-e6d8-4f20989f8639"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e9e8e493e784dcc9585278f2d21bf48"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = './custom_qa_model'\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(name)\n",
        "\n",
        "# Push to Hub (your username/repo_name)\n",
        "repo_name = \"Noobhacker69/Custom_QA_model\"  # you choose the name\n",
        "model.push_to_hub(repo_name)\n",
        "tokenizer.push_to_hub(repo_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "01a20b48bf484fed9fbc9a042d697d0a",
            "2c8900ca93174c3eaa0aa2b772b2d9fb",
            "0d5b6659782c4f20ae261a78954e954a",
            "f454dfdf9c454a7497d79258e3bc2114",
            "85c2514a62fa4344acbd1449ec4cb1e9",
            "4f6322bbf64d494eb914ca1f7af33158",
            "00643283662e49b3a6ad11fa03801e9d",
            "4c482f4b205444b1b56c6df82dc3a749",
            "c10d508ade24458cbbc3c9112e157fea",
            "affa953fe5f243c4b5af33699c54123e",
            "8a848b9652204278ae3f184b971f9239",
            "5aaa54d6c241441da92e407e0bc53fcd",
            "c848d9f544cb4fb5accc1409bc8d20eb",
            "cb4eb9fea1bc4d36b2837386028111e1",
            "7d7b0adb7fb14afb92e2063510e0c16e",
            "ae4d6fbb967f48479cb88d8851445702",
            "74f790f678f54194a91d1036efa5001c",
            "15db23df33854b2691329eafe4da1a67",
            "94447a812a78428c8ae83e85cf7a97e5",
            "02fc545473da43d7b973d93053e8859a",
            "cd6001c336314063ba5c9caf19d9d2a9",
            "adf29ade504b4f5e9e517a32f9212e75"
          ]
        },
        "id": "mOZ3KUNwWQVT",
        "outputId": "86edcad8-7c8f-4d8d-a904-e201b7f3323f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01a20b48bf484fed9fbc9a042d697d0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aaa54d6c241441da92e407e0bc53fcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Noobhacker69/Custom_QA_model/commit/97d9169d01dd10366f4dd4f149b92b8c748ca2e6', commit_message='Upload tokenizer', commit_description='', oid='97d9169d01dd10366f4dd4f149b92b8c748ca2e6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Noobhacker69/Custom_QA_model', endpoint='https://huggingface.co', repo_type='model', repo_id='Noobhacker69/Custom_QA_model'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "pngHJ474WzX4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_name = \"Noobhacker69/Custom_QA_model\"\n",
        "qa_a = pipeline('question-answering',model=repo_name,tokenizer=repo_name)\n",
        "context = \"\"\"\n",
        "Transformers are a type of neural network architecture that has proven very effective\n",
        "in natural language processing tasks such as translation, summarization, and question answering.\n",
        "\"\"\"\n",
        "question = \"What are transformers effective in?\"\n",
        "output = qa_a(question=question,context=context)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "a2ca4e3c4af044e887214a78d1eaff68",
            "f6106b61a60641d5a2333a70617d9e9d",
            "bdae8d0310134144be6edaffd7ba3832",
            "e7e9d2d5631840e89330f860ed3c8c87",
            "02f0fbaefbd84b04905147bfa755d0bd",
            "4f0b21549a764b40971c10b026a70637",
            "068805837cf64c88bed62d511c376077",
            "500390dbfbd245ff939b1fc271a3e0fa",
            "32a02f917d1e499586446c891ae0829b",
            "315dff891ec143ff888843b5c2d96cd8",
            "ae3de86705c54e66b4d70f3f5ef7543c",
            "6e07fe657e3e4750959e142765010bae",
            "2c28d8faf793414ba9ecf3b8b3783e87",
            "c1b57691f203421899081cad8f870708",
            "ff4fb013e2bd4277a09ffb76c19441a5",
            "771f0334bd4f47c6b4d09cf4c6323fcc",
            "d5f3b81a53964c30a930af8a5883822a",
            "bdcf378ff5a648e4b252ce9f2464c56c",
            "dc1abc45ea1741bba9c628d7f5ac6387",
            "8908af9b46d44ace8997ebdee2fe7e0e",
            "dc8883cfd1c7493ea501b00f14ff84d5",
            "43856288d19b4d0b89d1863bfe1da962",
            "d96f004acc9c4ee1996236f700a400f3",
            "c91f3fccb7e144e19a013828ae95b7de",
            "a0b71da536f04441b5f8279723ca0715",
            "efb10f20b22f43949edb9a3188ee8d59",
            "d189f1eb6c9d4c09a2873c97061763f9",
            "598ffc51ca6d4ad29b7688e3b0948fe1",
            "1bdeececf0c84fdbb1a40d5503e79a51",
            "5a7b6edc09ab4cda84eaedb6b4647312",
            "72aaee0c2b91428690110d508777e2e9",
            "9ff21b3fb1094b3c9f5f442fbc27acc3",
            "3421bb0d97e14c538850beb8b7fcfd81"
          ]
        },
        "id": "QxUgPn5MVUlN",
        "outputId": "cde3d3a3-b6c4-4234-fca5-6a1cebee91ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2ca4e3c4af044e887214a78d1eaff68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e07fe657e3e4750959e142765010bae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d96f004acc9c4ee1996236f700a400f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.05956058204174042,\n",
              " 'start': 28,\n",
              " 'end': 55,\n",
              " 'answer': 'neural network architecture'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvAUD4kuVy4u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}