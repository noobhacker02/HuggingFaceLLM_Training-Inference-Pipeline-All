{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "So NER needs to have token and sub token level tokenization and understanding so we use custom function and also used custom metrics eval and sequel as we need to check sub token level of accuracy done in QA models as well\n"
      ],
      "metadata": {
        "id": "crziG12NH6bI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "vigoL6Si8hFc",
        "outputId": "9619802f-85cb-4e1f-b18c-040c2ac0f51a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==3.6.0\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting filelock (from datasets==3.6.0)\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting numpy>=1.17 (from datasets==3.6.0)\n",
            "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=15.0.0 (from datasets==3.6.0)\n",
            "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.6.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets==3.6.0)\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.32.2 (from datasets==3.6.0)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tqdm>=4.66.3 (from datasets==3.6.0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets==3.6.0)\n",
            "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.6.0)\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting huggingface-hub>=0.24.0 (from datasets==3.6.0)\n",
            "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting packaging (from datasets==3.6.0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from datasets==3.6.0)\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.24.0->datasets==3.6.0)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.24.0->datasets==3.6.0)\n",
            "  Downloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets==3.6.0)\n",
            "  Downloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets==3.6.0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets==3.6.0)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets==3.6.0)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets==3.6.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets==3.6.0)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets==3.6.0)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets==3.6.0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.6/355.6 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, tqdm, six, pyyaml, pyarrow, propcache, packaging, numpy, multidict, idna, hf-xet, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, python-dateutil, multiprocess, aiosignal, pandas, huggingface-hub, aiohttp, datasets\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.5.0\n",
            "    Uninstalling xxhash-3.5.0:\n",
            "      Successfully uninstalled xxhash-3.5.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.3.2\n",
            "    Uninstalling propcache-0.3.2:\n",
            "      Successfully uninstalled propcache-0.3.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.6.4\n",
            "    Uninstalling multidict-6.6.4:\n",
            "      Successfully uninstalled multidict-6.6.4\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.9\n",
            "    Uninstalling hf-xet-1.1.9:\n",
            "      Successfully uninstalled hf-xet-1.1.9\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.7.0\n",
            "    Uninstalling frozenlist-1.7.0:\n",
            "      Successfully uninstalled frozenlist-1.7.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.19.1\n",
            "    Uninstalling filelock-3.19.1:\n",
            "      Successfully uninstalled filelock-3.19.1\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.20.1\n",
            "    Uninstalling yarl-1.20.1:\n",
            "      Successfully uninstalled yarl-1.20.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.34.4\n",
            "    Uninstalling huggingface-hub-0.34.4:\n",
            "      Successfully uninstalled huggingface-hub-0.34.4\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.12.15\n",
            "    Uninstalling aiohttp-3.12.15:\n",
            "      Successfully uninstalled aiohttp-3.12.15\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 datasets-3.6.0 dill-0.3.8 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.9 huggingface-hub-0.34.4 idna-3.10 multidict-6.6.4 multiprocess-0.70.16 numpy-2.3.3 packaging-25.0 pandas-2.3.2 propcache-0.3.2 pyarrow-21.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.5 six-1.17.0 tqdm-4.67.1 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "dateutil",
                  "numpy",
                  "packaging",
                  "six"
                ]
              },
              "id": "b298caa7792d46568ba5f2ed1db6f1ce"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install datasets==3.6.0 --force-reinstall\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FbZ3fjnh9oYR",
        "outputId": "8a183833-ddc7-4cce-d2b9-56a61fd76a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Collecting seqeval\n",
            "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.3.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.3.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "Tchxb-bq8un8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"conll2003\") # loading the dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403,
          "referenced_widgets": [
            "56f054122188434a976f481ac33ef08f",
            "61a78278efdd40e8b39ce0f6064362c8",
            "04d4adc17b204aab86f7ada38714d62e",
            "6b3d167255714a0a83dcb1a3a7a5318a",
            "23da20381c814d71b612bea651c2fafc",
            "09231e7dee41488c949fc93928f9558e",
            "af205a2d18f84cc7b429912bc9388424",
            "c0fa7881bdcb451f886acdc4d886c426",
            "e6a0155162fa436bb7b1410388972847",
            "66b011338dcd46acb88650616379e67a",
            "50c4d4f3ca0742819d00d275a3406c26",
            "69aac7b2ff2142c88ea9caa143269efe",
            "ed822237d2664b729a5b86b9355880cb",
            "b9b203726ee9412ba22d870688534016",
            "f20d1b0a81ca4ba7a906e8aff8638e9c",
            "d5fb0b25834144abad082debaa6b1245",
            "3c8b31e40b134bca9b8980c505402df9",
            "e22d1841ce7c457595c26f485373dda6",
            "9668d8254da447b68968ca5df93e8670",
            "e98c9a4353464aca81ef44b25c933aec",
            "17978cae9dde42f8b55d85d0e7364f2d",
            "8d011b738a9049e6b58c87e16f6d4849",
            "ad3f07cf352647549f9e641fccd0ece0",
            "6967520bcce2413fb277fd99c76fe945",
            "e02d0e94694443c093a5d5d777d3904a",
            "e2d168985ab84c7cb02245e61bda5fad",
            "e571d923f11e4119b354b8cfa05dc4b4",
            "d67c7bca7c034e3c8ad3bd2a4ef2056a",
            "ed623c5559284ed3a385daf37bad1762",
            "7e0de33579ab4976af22f0bae726ad04",
            "e3e16c7199044fbb866a3d888d65be3c",
            "26f7906a43fe4cb389a6538edf9532f8",
            "fcf1362dea4a449f8bf10005ac56ca3a",
            "02353c8376da4816b3233c3200484415",
            "7a54182d4dcf46db84c0de7a3e960ba4",
            "fe73c432c2814b2eba4bc4ae02ed8e22",
            "f6188463643d4bd2a2a7990e9b868651",
            "370a7dc65a4247fd89b2e29e9db7a998",
            "d240c7b7082446a9ab1f5fd480b6acde",
            "26e1c57805bc4737abee79a962328715",
            "92f976d08f27471192caa30f64b041cf",
            "5dc009e6ccc447a5a6bc6da2f452f718",
            "beb920341d2c4454a3c39b8b558cb6c5",
            "fa3dcca44f2b4a1392675b39b4b606a0",
            "80cf9c89a6da4255b3700474e4f27742",
            "203e38df47f04c15bc72bb27c826784a",
            "bccdbb9127804913927c643d4468658a",
            "5047e3d8ebab48b9bfebf816f3069da7",
            "7190dc945c0e4c0fa9ded4c2b0a19ad8",
            "33246ad52b064280825e73641424e2a5",
            "fec53e5988b644d7acb24297239007c7",
            "f6612aa63e0742eb8fe9ccd3f4af5c13",
            "f138c1c0e8194aa58415123e7c869312",
            "27d79a4ac6d940828c4817c46d8cc2fa",
            "1bf6a3d9ef674a2c92bb0c7dfd88999d",
            "48dd6fe91a3a492caac19b2708eb9c8b",
            "943391f2f25f4a3fbb5d7512b06809e4",
            "958687b00a3846419e597f9f8f1770e4",
            "4cd5961adb67458cb3625eb7c267c382",
            "2a09ce65ab91418e8bec2ae75ba7a8c8",
            "e3318e56b08d49d0948042ed563b368a",
            "2f8da9074d0f4f57a469be9d91fc1502",
            "61ef9c2d727e4a8f8e3f8c5135f17c31",
            "4cb0788b389d4e3caae6eede630ccb6c",
            "c0d510ebd9794db8965ebbbd4ca46d04",
            "5595d234967f47a9943af3140029eb36"
          ]
        },
        "id": "p-r0sbB383Fl",
        "outputId": "c0ccbe11-e7de-4c11-cccc-10f66d52c573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56f054122188434a976f481ac33ef08f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "conll2003.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69aac7b2ff2142c88ea9caa143269efe"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad3f07cf352647549f9e641fccd0ece0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02353c8376da4816b3233c3200484415"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80cf9c89a6da4255b3700474e4f27742"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48dd6fe91a3a492caac19b2708eb9c8b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names # extracting features from this dataset for feeding to the model\n",
        "id2label = {i: label for i, label in enumerate(label_list)} #giving it id2 and labeli2\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n"
      ],
      "metadata": {
        "id": "v75ogeys85I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting checkpoint as untrained bert\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "faf3dafc394c40e2b3dc9486ff443856",
            "4f5aa981a7c84eeea13de1bbd9e15571",
            "4b0801a19813412db1e55db87f791d3e",
            "87ef9f748d1543b1bcaea51e374f79b2",
            "2212ce9eeb5a456b9d7530472d05334e",
            "c12e72355f1547d0b0d2f4eadcff223a",
            "f4407d3d6e11461bab2b7a891640501e",
            "e154e05ed8b04e30a8f50586b5c2484d",
            "88f5623993904f9c898cf779d6971ed6",
            "91cd7a43e7004ec1853a1b4a19baf9d8",
            "6eb7d94b861240a1ad43461bc90577d0",
            "730879aaa1964c7c82a15da40bf7e53d",
            "7dfa7cd282204b2bb676d9b427852600",
            "b987e5fb4de54c398789e7f69281ad38",
            "134eac0cc22448a3a64f1a79d2691253",
            "2a6dc7c2e94442da83abed820c39feb4",
            "7a1a7f73ba9c4e8f9fbab9d6f7cfd639",
            "e97107b71a3e480ca21f526fcb053b71",
            "cb871cb0246b4f36bb8eb0f0950cef49",
            "c2c4bc46a50e4324b1eb171e02fefc35",
            "9af8133797204bc9bbcea916fbde9236",
            "6159198ab4d84e50a29ef1605148e682",
            "bfdbdbe11c7d4cdb8f3b49e038669238",
            "e35b9ba147404965aa9d30289372f9de",
            "a8b70ef16a32454aae0df280440288a2",
            "c6f9b2c035c94be9b18722286f9a76bc",
            "0bc057a6ddd44580bc1cef1833b3d58d",
            "c03c79583de9421fbe48bc72d2102785",
            "49e352e3528b49cd9704ded9ac339b29",
            "9ae4d00b99f2494d9e7aaf95cc4635da",
            "2465086b68c444029b7a5101088f4e1c",
            "a7a5f2937aa64ca8943618aa65e34343",
            "c9db72609b7f471c944626eb7589e672",
            "2dd62f2f8c1e4f81baf5b90ed6460a82",
            "157c27dcc4e5436daa7006803297022b",
            "b837c16515f34d76b61ac866c63e36fe",
            "b72c273fc9274fc7a2c786f7da55593a",
            "437c9ebb5d944770bae7d9b03c0aaa81",
            "7c943fbee6f545f5b3a9c5375761bd1d",
            "5407fac968c14df382c1048ee8688180",
            "6a83bd1ac9574388b7f274b5d39de190",
            "e9054262d9ba4174830d6c1438b66190",
            "86e73b076ad54374bffe135d2396a839",
            "fb785cbf53174d4abe6a25d2bceb9a6d"
          ]
        },
        "id": "h0QHNrIX9MMm",
        "outputId": "897627c3-bb1a-4fa0-de6c-7dfc61c3d2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faf3dafc394c40e2b3dc9486ff443856"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "730879aaa1964c7c82a15da40bf7e53d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfdbdbe11c7d4cdb8f3b49e038669238"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dd62f2f8c1e4f81baf5b90ed6460a82"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing each word and subwords\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,  # Important for word-level tasks\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)  # Ignore these positions\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                # For sub-tokens, you can either repeat the label\n",
        "                # or set -100 to ignore them in loss\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n"
      ],
      "metadata": {
        "id": "mbKRKczo9smJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#batching and tokenizing all data in dataset\n",
        "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "a612e001c39b4d3ba581c29fbdf5f6d3",
            "735601eff8c04162b0c3dd9581a7f81e",
            "d92c18bf78b4456f984646233b47847b",
            "9e836c8140354b198e7845389045e5d9",
            "ad97cc0d9e7040789a85de437bfafddd",
            "37605d60116b43c2a283f0086a3f823a",
            "aa59676f74db4326a3ee0ca671d5af18",
            "2f63493065f043bfb9f31d0dc1ec0e0f",
            "3b17babe1b4a4ba58c031ba7803b63cb",
            "7a27e72c2be24e39bc918b407d2a2116",
            "80e79a7097724537a921a8019fba499c",
            "1205881e432c484e9b55ace22df73307",
            "fb035b3eb4c64f42aadae51f2ccad18f",
            "6c2ea2b006a748b484a307bd929f880c",
            "4ad7231437a84fb3bdecc6aca3f1836c",
            "d046df81e3594e1ba39050c48d91249f",
            "eac8381fe50d442797b614e07338e3b7",
            "bb04dc466df0480aa6c58e187637fa94",
            "2ae6690184354d3cb5ee44f4ed0d403a",
            "86df326cb2924b45a96f0e4904234d74",
            "374429522f3d46419ce7723ec63ce4be",
            "d8e3f7e6463a45e7b464e0ed6bfc2f6c",
            "9995056ddeb14195b71137911a1e4385",
            "77d120b258674da79254fda2a718128b",
            "f849bd5470fc4de7a4669b819ff28c58",
            "efef90b5db4d46fb84ee1c7a8fda0d1b",
            "bc42543b6c0e48029ed00d1eedbbb97e",
            "45f68f3ea2bd4736848d3895d2415d79",
            "115bb68272fe400aa41c68c831ce7ade",
            "7c8a312ab7e14c308079dbe0b1fe62e3",
            "5ab0c19b90034375b7a6282917d80af3",
            "c7c3f0b357bc429aaaeaf650be2acb75",
            "a6e912d3ff004cd2b6a0eb3456e9408f"
          ]
        },
        "id": "HeoG4A4W91OL",
        "outputId": "0b870534-873c-47ef-f76e-8a920632adc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a612e001c39b4d3ba581c29fbdf5f6d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1205881e432c484e9b55ace22df73307"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9995056ddeb14195b71137911a1e4385"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n3k-1DvJor-",
        "outputId": "7a9a594d-9c94-4b27-cbf9-6c74caf4ca66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlTDd8P5OFUK",
        "outputId": "ac9a9bba-30b4-4333-ab13-b0757d287273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model and setting all checkpoint model and label/logits\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e570abe2ef294f608abaffd7e7eae6f6",
            "0b273191eb1b471b91524915c23bfb92",
            "bea26497889b4684b27567b6928d1af5",
            "da37717d9049405fa4248374b45bf01f",
            "db8e75d5ab3143fabfbb763e724fa61a",
            "954ca5d30fe840a58972f53d942e6689",
            "1135a2d74d964367bdf0b277e118cd54",
            "747487ecf40c43c2b066bc96b82ae904",
            "c18f555fb96c4ec8b40b4866c6e71914",
            "f62a5f2dbdc241fbae9e3202980a6ef3",
            "4ae418d9e74a424d8a588cdd53b73830"
          ]
        },
        "id": "J7ddULlMOzGR",
        "outputId": "22361b66-4716-4443-d590-7491accb31e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e570abe2ef294f608abaffd7e7eae6f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)#establising the collator wont be used as we padded it to max len in tokenization but still"
      ],
      "metadata": {
        "id": "1AhT6-MxPk3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"seqeval\") #as we need custom metric for subword anaylsis we cant use only numpy we use this as well"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "02372068eb3b4f708a7d41843b9ecc0f",
            "ad64b1c307b047ce9dac7da873370491",
            "36036d4e325e42489c7b61f004c20612",
            "6e5052edfee44db3b212336ad4215183",
            "b51d6a9fb4104f24a5ff32dc3e6d077a",
            "0b87643612054d558fadd8af17d7c8de",
            "3b58fc990523455389bcaf0d267c0d3f",
            "0446d87a66e7460ab8fc6d9be980d443",
            "9e0c389b9cd04677a4700c6753155ca2",
            "21adca01638643d4baddac3c14496efb",
            "147813eec92c42a996bf1b78268588a1"
          ]
        },
        "id": "YNmwft5nP10R",
        "outputId": "8a763e79-c99f-45b1-aa2a-2eb8c9121457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02372068eb3b4f708a7d41843b9ecc0f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we use metric function called seqeual which we imported above to use  in fucntion compute metric for checking subword accurracy in all cases\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (-100) for true labels and predictions\n",
        "    true_labels = [\n",
        "        [id2label[l] for l in label if l != -100]\n",
        "        for label in labels\n",
        "    ]\n",
        "    true_preds = [\n",
        "        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_preds, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "hu4xxPSNQIxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base Training setup\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ner-checkpoint\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    load_best_model_at_end=True,\n",
        "    #fp16=torch.cuda.is_available(),\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    logging_steps=50\n",
        ")"
      ],
      "metadata": {
        "id": "tEK6ZebJko6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic Trainer functions and agrs\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioQ0oMxSks8c",
        "outputId": "1f921b67-56ec-422c-a65d-a93e49a0a01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3178454214.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final training\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9YvqqUSmkv3q",
        "outputId": "b2b27ea8-a317-48d6-93e8-eb63aee3408e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2634/2634 16:20, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.055700</td>\n",
              "      <td>0.051741</td>\n",
              "      <td>0.925715</td>\n",
              "      <td>0.931638</td>\n",
              "      <td>0.928667</td>\n",
              "      <td>0.986132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.026600</td>\n",
              "      <td>0.050823</td>\n",
              "      <td>0.932116</td>\n",
              "      <td>0.945614</td>\n",
              "      <td>0.938816</td>\n",
              "      <td>0.987243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.020900</td>\n",
              "      <td>0.051216</td>\n",
              "      <td>0.936979</td>\n",
              "      <td>0.946287</td>\n",
              "      <td>0.941610</td>\n",
              "      <td>0.987983</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2634, training_loss=0.06125767724751159, metrics={'train_runtime': 982.1828, 'train_samples_per_second': 42.887, 'train_steps_per_second': 2.682, 'total_flos': 2751824963545344.0, 'train_loss': 0.06125767724751159, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "FQ5dskHmk9Lv",
        "outputId": "07c6d39f-2c35-4239-b859-3a1b19c49bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [216/216 00:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.11444572359323502, 'eval_precision': 0.8863518422418267, 'eval_recall': 0.9075451647183846, 'eval_f1': 0.8968233132055659, 'eval_accuracy': 0.9789768443726441, 'eval_runtime': 24.499, 'eval_samples_per_second': 140.944, 'eval_steps_per_second': 8.817, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving model and adding config for id2label in model\n",
        "trainer.save_model(\"./NER-distilbert-finetuned-custom\")\n",
        "tokenizer.save_pretrained(\"./NER-distilbert-finetuned-custom\")\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iRVohYhmM4r",
        "outputId": "075a06ea-dfa1-4dd9-ee78-7589fcbe4864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./NER-distilbert-finetuned-custom/tokenizer_config.json',\n",
              " './NER-distilbert-finetuned-custom/special_tokens_map.json',\n",
              " './NER-distilbert-finetuned-custom/vocab.txt',\n",
              " './NER-distilbert-finetuned-custom/added_tokens.json',\n",
              " './NER-distilbert-finetuned-custom/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_code = ''"
      ],
      "metadata": {
        "id": "c2px1tbom7A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "05d07cff426549d0af1355c7a77e46af",
            "c231d8750f154a5e849ec592127879c1",
            "91b03c4f95ff404f876fc301664a1c6e",
            "6c582c1f04b845178b85c1717d6431c4",
            "2642362b38ae484298568c042a959939",
            "c01eed1999fc4a8695fd2bd208446b30",
            "9128aaf903f5420295daee3eee004915",
            "4296c8c702944c3882ec2d2d3e30b2ab",
            "3ab2d0e8826647d599770c0c78cd5fd9",
            "2fc1f112239148c0badb443517f9b8f5",
            "ac04f564315741668728fc7cbb314188",
            "73bb3409b35f4f389182c4fde60529fa",
            "529e2481bf384b368a10ca2e3e2e145b",
            "4f8d8f7f4c934810b94a7c34bfefc78a",
            "4893ee44d0fa45d3a02d8ae5397dd452",
            "baee08d7179c4f8e82b10d1dc124cfcc",
            "b31818ced4dd4215bc600a37c19ed746",
            "d5ebf841440d454aac7e9d4b5be0fbb8",
            "af9c8622f69e41f2a4d9cfea966a02fd",
            "1c4a2a33972e4247beaf4a9d9e8cc173"
          ]
        },
        "id": "-BBZyxt-uU-u",
        "outputId": "64e5bed6-f9e8-450f-bbe6-f62d2b8da05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05d07cff426549d0af1355c7a77e46af"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"./NER-distilbert-finetuned-custom\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./NER-distilbert-finetuned-custom\")\n",
        "\n",
        "# Push to Hub (your username/repo_name)\n",
        "repo_name = \"Noobhacker69/NER-distilbert-finetuned\"  # you choose the name\n",
        "model.push_to_hub(repo_name)\n",
        "tokenizer.push_to_hub(repo_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "bd6925aff7094ac291a5ed86a3ead3e1",
            "54da6044f13a4c81ac19b5870678f1d9",
            "e8450d0e6e524ec5808a078aa8196df0",
            "ef23d5246f4d46a29d0e66fd02b89fe5",
            "d77c295a1c124241868ad2a9680a652f",
            "35a1f5ddd08542ae947dc3800b04087f",
            "3bd636cd70cf4fffb7d79e7b5d100f7a",
            "2c0044e7b0384edb8d50252336d0e3ce",
            "0ec05829a2b74e9788c60c1a06a2cc76",
            "e618c4ab027c46ffa4bfd3c5812112b0",
            "d8da2d7350c946328dac6356bf2f3a37",
            "82aaa7f9276a4d95bbb7faaacb6fce45",
            "04e3c45f4f2241469527ff150696c859",
            "1bd4f823ba584f37a684f45e89840c09",
            "0cd80cf7649949e880f32a419ff05747",
            "c9d0ed442e9944e5ac87ac1dcf55fb09",
            "e82f52b3bae141e6b61251880e0259c7",
            "66885cca07e04c8d80eff80979a45712",
            "19d3b374f3764ba185fb39a009551a61",
            "17468a21fc3f434590fdadfe25364db3",
            "dab47214e0124c7d986c0b3a3090cc5b",
            "0e95f55361284fbb86a1282cb8a8c0cd"
          ]
        },
        "id": "ti8GA3DDuW0R",
        "outputId": "ac01920f-759d-4705-a60e-f494b8ec0eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd6925aff7094ac291a5ed86a3ead3e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82aaa7f9276a4d95bbb7faaacb6fce45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Noobhacker69/NER-distilbert-finetuned/commit/6c853351b8f05f9d1bf3db5e54a3b445a5b886d9', commit_message='Upload tokenizer', commit_description='', oid='6c853351b8f05f9d1bf3db5e54a3b445a5b886d9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Noobhacker69/NER-distilbert-finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='Noobhacker69/NER-distilbert-finetuned'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "import torch\n",
        "mnameinf = 'Noobhacker69/NER-distilbert-finetuned'\n",
        "model = AutoModelForTokenClassification.from_pretrained(mnameinf)\n",
        "tokenizer = AutoTokenizer.from_pretrained(mnameinf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "4ef4c08d2f214f05b0901fc5a98d057f",
            "0647794d4034477ba44e10859bc1fa01",
            "e0bdc3e5393a426ba77431d7d505da9e",
            "af3408c04dcc4396a5834b5c066b6463",
            "e2b6e5978270449899e10f12f0b65fc5",
            "97d6f79299f549f0a0527dc52037ae6b",
            "afd477f5aabc45f497b1479115b1e1a6",
            "1ec67b30476044ca8696c60b01bb8c71",
            "a129def1f05d4b1db3a7469c9d46e8fb",
            "442d6eef780d47ac8911cbf4d515063d",
            "5420615b53a9417ca7cd8d035931f6c6",
            "509a16bc6e74430ab111c8f00c24613d",
            "9369f03937584b0cb8e3898ebe229032",
            "5c0d3164fd19461299f985ce51d08ffd",
            "3550da8dc8194acb8dc6fb7e5592ed72",
            "421cb5fa3faf48fea60c4060c5e2fdf2",
            "3d8942dfd105409ebe1aff8480f32e94",
            "bd853d7d764f4ba3af29deaf34062513",
            "b189e462723749328f47f26043d30d8f",
            "6154c27c8acf455d9c8cb2f6d4d326f2",
            "9a0ed1173744489085861c5c202eac05",
            "0f03161d4bfb4e3581aaadc7326e39ea",
            "6f7ad2d9ed344e108481f91b6b055c53",
            "0f802915918145b1b8f5eb274776d5c6",
            "0e21c4d7a6b540fdb0a510cae487167f",
            "a2584eae790d468890cf18bb9a0e431e",
            "0ee6db2325d04dea8c5c35da158a59b2",
            "9ac018b03a2b4811b98d8acc01cd7f1c",
            "f0063a43415d481286592a7fdd0e4332",
            "7b8ce4361fcf47b380310c818b7ecb11",
            "f8b0849efa3c4f4da9a99a009fd6f5b6",
            "759a9fafffd54051917916b7905acc0e",
            "ff003976bfda4ee3a6f4a743d72645ac",
            "00397139e3ca4ea3a7b3ac09c07cb54a",
            "e2e081dd35734033afc9cda9206b9afb",
            "d72028f9c50b4991a0d57312fdd78328",
            "c4e3f81a239b421c942cd8a9d02e11c9",
            "8abdad5a04f14b469238285ef2b621a9",
            "e032b7ebc355441aa205445a783c58ef",
            "9e2e44e70cc14e18820e97785b711b25",
            "a2e645187fc346579e357f71f94346c7",
            "e0b74527fb3f4b05b5acb7a4b62fe845",
            "a0c9ec9fd9d04f50a88ae4e56638d57d",
            "17a134f6e237433cbee018b3f397527c",
            "eceaf6a1673b4effb9a1de7684adaf45",
            "0ee3e94cf2fb44d58a6f3fc25ccc675b",
            "ace9188b2cb94623bdfa05aecee94256",
            "7651417c3438402f862f370ac8ed8fbc",
            "995df36a645d4123b0695861bcde54c6",
            "48b457aa62e545aaa269d79901f2ed0c",
            "b6e93f4245a841958fb100610071e4d7",
            "f761497003894333bfb691dfd4de549f",
            "2adee335509a4b928f235ab5039cee88",
            "cd5a33e358ff4aa88dca81d4e165f9d2",
            "19599e15755a41ada82646d031c66907",
            "dfce81fd84ca4e4c8f60fd6486e475a1",
            "cdc61e721a944295855c8c316e4f8a4f",
            "36d105e40d9644eaa370be1d008fefd4",
            "d57ed40b59ec488da250ef6d9627f419",
            "bd824c220adb4bbcb57636bc3547ca0f",
            "9e58e0740d8e46478e97f01f410bc494",
            "b8e500fb13764410849002bc036add33",
            "780e8592c7c94d2bb19006c9419ee5e5",
            "a810bd4e02c7408781d544d46a9b6c2d",
            "e4d5c8ea4967401489f0d088ece81248",
            "fed2503d2e6742fd9b2b9c3bf1126dda"
          ]
        },
        "id": "pLZZwJU8d-JY",
        "outputId": "3764a74a-d330-416f-abed-0f312b299f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/971 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ef4c08d2f214f05b0901fc5a98d057f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "509a16bc6e74430ab111c8f00c24613d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f7ad2d9ed344e108481f91b6b055c53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00397139e3ca4ea3a7b3ac09c07cb54a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eceaf6a1673b4effb9a1de7684adaf45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfce81fd84ca4e4c8f60fd6486e475a1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input='Hugging Face was founded in Paris by Julien Chaumond.'"
      ],
      "metadata": {
        "id": "KTSi6S4kCQZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer(input,\n",
        "          padding=True,\n",
        "          truncation=True,\n",
        "          return_tensors=\"pt\",)#putting padding cuz inferece and truncation"
      ],
      "metadata": {
        "id": "57cvdfYsNIOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  tokenwithlogits = model(**tokenized)#no graident calculation and getting logits and results"
      ],
      "metadata": {
        "id": "3wOWtiEHNf-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenwithlogits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2kr-8gAP6nD",
        "outputId": "6dd44a21-8f16-4b44-b03a-367c3d6e87ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TokenClassifierOutput(loss=None, logits=tensor([[[ 9.0921, -0.9132, -1.4372, -0.7800, -0.9474, -0.5659, -0.7696,\n",
              "          -0.9978, -1.0889],\n",
              "         [-0.3923,  1.1802, -2.0384,  4.8663, -1.7768,  0.1385, -2.1369,\n",
              "           0.6245, -2.1418],\n",
              "         [ 0.8769, -1.6000, -0.2680, -0.3183,  5.4767, -1.5505, -0.8979,\n",
              "          -2.2523, -0.4133],\n",
              "         [ 7.8669, -1.7274, -1.4732, -0.8619,  1.5679, -1.3786, -0.6423,\n",
              "          -2.0718, -0.6811],\n",
              "         [ 8.7131, -1.4320, -1.7222, -0.5167,  0.3809, -1.0770, -0.8794,\n",
              "          -1.3706, -1.2866],\n",
              "         [ 8.9517, -1.5011, -1.8404, -0.9545, -0.3054, -0.6821, -0.7103,\n",
              "          -1.5513, -1.2707],\n",
              "         [-0.5956, -0.7878, -1.4985,  0.3490, -1.1584,  7.4845, -0.2393,\n",
              "          -0.8597, -1.7415],\n",
              "         [ 8.8037, -0.6030, -1.5508, -1.1640, -0.3858, -1.1249, -1.0119,\n",
              "          -1.3431, -1.2752],\n",
              "         [-1.3599,  7.1974, -0.8212, -0.0376, -1.7612, -0.5614, -1.4725,\n",
              "          -0.7433, -2.1703],\n",
              "         [-0.8860, -0.1919,  7.6458, -1.5865,  0.1754, -1.0684, -0.3731,\n",
              "          -1.0437, -0.9342],\n",
              "         [-0.8001, -0.3343,  7.4884, -1.5504,  0.4737, -1.0901, -0.3571,\n",
              "          -1.2492, -0.9057],\n",
              "         [-0.7670, -0.4488,  7.0670, -1.8929,  0.6963, -1.3053, -0.3255,\n",
              "          -1.1760, -0.9924],\n",
              "         [ 8.9369, -1.2057, -1.3655, -0.9652, -0.3726, -0.8155, -0.7080,\n",
              "          -1.7158, -0.9936],\n",
              "         [ 0.3036,  0.1261, -0.9086, -0.0189, -0.4264, -0.0496,  0.6441,\n",
              "           0.2405,  0.7067]]]), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits =  tokenwithlogits.logits #getting logits from data\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pINYZ_1uOBVm",
        "outputId": "a948ef7e-51e4-4f4c-9b68-8377c3465f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 9.0921, -0.9132, -1.4372, -0.7800, -0.9474, -0.5659, -0.7696,\n",
              "          -0.9978, -1.0889],\n",
              "         [-0.3923,  1.1802, -2.0384,  4.8663, -1.7768,  0.1385, -2.1369,\n",
              "           0.6245, -2.1418],\n",
              "         [ 0.8769, -1.6000, -0.2680, -0.3183,  5.4767, -1.5505, -0.8979,\n",
              "          -2.2523, -0.4133],\n",
              "         [ 7.8669, -1.7274, -1.4732, -0.8619,  1.5679, -1.3786, -0.6423,\n",
              "          -2.0718, -0.6811],\n",
              "         [ 8.7131, -1.4320, -1.7222, -0.5167,  0.3809, -1.0770, -0.8794,\n",
              "          -1.3706, -1.2866],\n",
              "         [ 8.9517, -1.5011, -1.8404, -0.9545, -0.3054, -0.6821, -0.7103,\n",
              "          -1.5513, -1.2707],\n",
              "         [-0.5956, -0.7878, -1.4985,  0.3490, -1.1584,  7.4845, -0.2393,\n",
              "          -0.8597, -1.7415],\n",
              "         [ 8.8037, -0.6030, -1.5508, -1.1640, -0.3858, -1.1249, -1.0119,\n",
              "          -1.3431, -1.2752],\n",
              "         [-1.3599,  7.1974, -0.8212, -0.0376, -1.7612, -0.5614, -1.4725,\n",
              "          -0.7433, -2.1703],\n",
              "         [-0.8860, -0.1919,  7.6458, -1.5865,  0.1754, -1.0684, -0.3731,\n",
              "          -1.0437, -0.9342],\n",
              "         [-0.8001, -0.3343,  7.4884, -1.5504,  0.4737, -1.0901, -0.3571,\n",
              "          -1.2492, -0.9057],\n",
              "         [-0.7670, -0.4488,  7.0670, -1.8929,  0.6963, -1.3053, -0.3255,\n",
              "          -1.1760, -0.9924],\n",
              "         [ 8.9369, -1.2057, -1.3655, -0.9652, -0.3726, -0.8155, -0.7080,\n",
              "          -1.7158, -0.9936],\n",
              "         [ 0.3036,  0.1261, -0.9086, -0.0189, -0.4264, -0.0496,  0.6441,\n",
              "           0.2405,  0.7067]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.argmax(logits ,dim=-1)\n",
        "data# max arg logits and getting results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V76lGfDGOGK3",
        "outputId": "db844a5e-52b4-4d1f-8754-c51fa9a0c4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 3, 4, 0, 0, 0, 5, 0, 1, 2, 2, 2, 0, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = model.config.id2label\n",
        "label2id = model.config.label2id # calling id2 labels from config model\n",
        "\n",
        "print(id2label)\n",
        "print(label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh7iPqg6Soy0",
        "outputId": "de258a39-8431-4ef6-f9ee-a4b0cf00071c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'}\n",
            "{'B-LOC': 5, 'B-MISC': 7, 'B-ORG': 3, 'B-PER': 1, 'I-LOC': 6, 'I-MISC': 8, 'I-ORG': 4, 'I-PER': 2, 'O': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_labels = [id2label[i.item()] for i in data[0]]# adding labels array/tensor"
      ],
      "metadata": {
        "id": "Yfzou-p4RUQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(zip(tokenizer.convert_ids_to_tokens(tokenized[\"input_ids\"][0]), pred_labels))) #using zip to print predlabels and outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLFbzEzHTdCI",
        "outputId": "ef7562c2-5072-49a0-e2e6-985981f1f39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 'O'), ('hugging', 'B-ORG'), ('face', 'I-ORG'), ('was', 'O'), ('founded', 'O'), ('in', 'O'), ('paris', 'B-LOC'), ('by', 'O'), ('julien', 'B-PER'), ('cha', 'I-PER'), ('##um', 'I-PER'), ('##ond', 'I-PER'), ('.', 'O'), ('[SEP]', 'I-MISC')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline('ner',model='Noobhacker69/NER-distilbert-finetuned',tokenizer='Noobhacker69/NER-distilbert-finetuned',aggregation_strategy='simple')# using agr startery for combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20ZoJhtzfv9b",
        "outputId": "29a2b53e-3df8-47f4-cafe-1932fbfd8771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = ner('Hugging Face was founded in Paris by Julien Chaumond.')#agregated results\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYXPB1t1fYPD",
        "outputId": "0691a039-bd65-44c1-87d5-439c727480c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'ORG',\n",
              "  'score': np.float32(0.96154726),\n",
              "  'word': 'hugging face',\n",
              "  'start': 0,\n",
              "  'end': 12},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9975641),\n",
              "  'word': 'paris',\n",
              "  'start': 28,\n",
              "  'end': 33},\n",
              " {'entity_group': 'PER',\n",
              "  'score': np.float32(0.9971682),\n",
              "  'word': 'julien chaumond',\n",
              "  'start': 37,\n",
              "  'end': 52}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = ner('Hugging Face was founded in Paris by Julien Chaumond.')#non agregated results\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBiRBaeeexFo",
        "outputId": "85dc62a5-48b2-4544-b546-426f7b05926d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-ORG',\n",
              "  'score': np.float32(0.94551903),\n",
              "  'index': 1,\n",
              "  'word': 'hugging',\n",
              "  'start': 0,\n",
              "  'end': 7},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': np.float32(0.97757554),\n",
              "  'index': 2,\n",
              "  'word': 'face',\n",
              "  'start': 8,\n",
              "  'end': 12},\n",
              " {'entity': 'B-LOC',\n",
              "  'score': np.float32(0.9975641),\n",
              "  'index': 6,\n",
              "  'word': 'paris',\n",
              "  'start': 28,\n",
              "  'end': 33},\n",
              " {'entity': 'B-PER',\n",
              "  'score': np.float32(0.99759465),\n",
              "  'index': 8,\n",
              "  'word': 'julien',\n",
              "  'start': 37,\n",
              "  'end': 43},\n",
              " {'entity': 'I-PER',\n",
              "  'score': np.float32(0.99789536),\n",
              "  'index': 9,\n",
              "  'word': 'cha',\n",
              "  'start': 44,\n",
              "  'end': 47},\n",
              " {'entity': 'I-PER',\n",
              "  'score': np.float32(0.99737144),\n",
              "  'index': 10,\n",
              "  'word': '##um',\n",
              "  'start': 47,\n",
              "  'end': 49},\n",
              " {'entity': 'I-PER',\n",
              "  'score': np.float32(0.99581134),\n",
              "  'index': 11,\n",
              "  'word': '##ond',\n",
              "  'start': 49,\n",
              "  'end': 52}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}