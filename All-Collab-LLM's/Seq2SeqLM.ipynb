{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "35vKvNBQsniF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oTzLkwPJWQGF"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text2text-generation\", model=\"t5-small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350,
          "referenced_widgets": [
            "2e02d1369bfe463aab6c1e08eca730cc",
            "7aa2b2a39a1940e38a380ca130c7485f",
            "f47e8e1cf445434bb08cdb68ac410bfc",
            "290518f00fb34dddb1a2ebcf3b4d2e17",
            "ece79aaea97e47d2a1da46dba7a96068",
            "39ffbdc2e4cd41539a4340696f3026dd",
            "d8eb3f305906422da7bfa03e00180473",
            "d6c6da1069624856b8ff1f30a2272aca",
            "8d5608a72a0e4efeb783a304bdf11941",
            "d506421840214755a58a16a6af7a26a6",
            "6f72a6d2317d482aa45fd7633997959a",
            "f03a5900d97341719162f2ce6faaa959",
            "c190a1ed802444c886569829d1e5038b",
            "27ba93a3db8342c88daed85a7da960bf",
            "be236df185b34e1c9eabeca54d35061b",
            "e1f88005dbae47faa4216998c864db9a",
            "5ea8132574a748c09e7b98305eb193ec",
            "e9a5091eb9c548c881ef992ceeaeac2a",
            "1da7f16cbc5440a9a16d4b0a35719109",
            "a9862e404e2943a4af6a4d1f64453b33",
            "6a5dc0d3b874468daa0e410fc95a5c0d",
            "15602baab15e4bdc8efa8a7bc3e33ee4",
            "9282191044964801b710475dbd788561",
            "41c593abb7c3435a934893245399fdc6",
            "0ccf5e93392b4da298f5c975e26310a7",
            "881d8c4ec63f4c69be6790e5b5e52613",
            "b9de8f29bd3a4bf4a6e2b96839dc7250",
            "7d0f908a5fbb44e3ab636d345de76f52",
            "30f462220b5347ada1a741c96b15216a",
            "941ff760b01d4a21834aff5a038d6e63",
            "d131783ef3e04af6a99d336d8485df27",
            "f77d65fdf01f4c6eb711e0385d271db3",
            "da83fb66a95c4a00902eb95d660fa8a8",
            "7435a8c2f2604f4aa1aa36a3458c3459",
            "18e7cb4660714131a9192f33b60deaec",
            "60a157c4c7d347e0b6beaa6cfb32693d",
            "38a235d36d9f4650ad1e4bb46b861fb8",
            "6833e42f70bb4d518900e9c733f1d593",
            "20d43b1c8b174af888fab4ce56c9981d",
            "5383be1cf72441059f78a0e22ea5cf4d",
            "d7e64967941944aebb792c19cd40190f",
            "9b60441174b64128bdabb183ef5358bb",
            "8be5a0f47831467e805d589751f3aa41",
            "3aad4b16a17e4664ad02e14e1774df8b",
            "20d656c9bb0c4903a70cc0aa7c688dda",
            "388ac922961f41eb833ed9e86340fb09",
            "1f88c959309c429cb95dad6e099c5ec3",
            "3b206f1d54f54830b0a170bf28e0f71f",
            "3005aa31a03c4692b6e88a8bf44eba36",
            "3bb41a69b6e3420880ec53316966fcbf",
            "414829f3105b44d39d482c94e9c88c9f",
            "f753a832742f4df0b58fff436465f7fc",
            "6b615acb9894480480e095a4a7ff13c9",
            "0952e25c7cde4835beb956b99d3e943f",
            "f208b9f76e484f8a98b51f225e2ccad1",
            "a9ecfbad716942e19bf8a1a1ce8de5be",
            "c202cd2fe58b46e4815ea53e4099a5f7",
            "13f9a0503a7f4096a2377937f5278264",
            "fc66a1d3cff3444e82df9644a8e10fd6",
            "be7a4af433d340edb93d1250ee8cbb8c",
            "d42b8b34aaaf4ea6a28fb34407f3e7e5",
            "2e45977fe573458484d544cef98e4a68",
            "13d39d2ed6fc4602b5d4fe29a018bae9",
            "cd745c511f164e4f97f79f159ba175fd",
            "150a50ea3a9d4aa696f1c1e4ffc8d062",
            "d79a76c51a4446c08fa2522394eb1295"
          ]
        },
        "id": "LMLsDxBysmmm",
        "outputId": "f0acb8cd-aa2c-4a5c-d2fb-ef1f7390eca0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e02d1369bfe463aab6c1e08eca730cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f03a5900d97341719162f2ce6faaa959"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9282191044964801b710475dbd788561"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7435a8c2f2604f4aa1aa36a3458c3459"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20d656c9bb0c4903a70cc0aa7c688dda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9ecfbad716942e19bf8a1a1ce8de5be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"translate English to Italian: The house is small.\""
      ],
      "metadata": {
        "id": "Zqg3MBo6stq7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = generator(prompt, max_length=64, num_beams=4) # beams is top_k aka number of top choices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNQnhL-Ms95A",
        "outputId": "964a2496-d0bf-4d76-a347-ddf5c0b9bb92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result #german"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuAAHpx8ucR-",
        "outputId": "fda2df49-e59f-4f32-e056-5cc2e85d1dfa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Das Haus ist klein.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result #spanish"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C9MIOAytFH-",
        "outputId": "f9377ff0-0e3e-4bef-d785-80e7baf32f4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Das Haus ist klein.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result #italian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uVoLqi6tskr",
        "outputId": "f284e019-147f-437a-d130-d6a7edd92d72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Das Haus ist klein.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[0][\"generated_text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3z0iHenFu-mi",
        "outputId": "f0aeb3b4-4e09-4804-89ea-6ec74a73e841"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Das Haus ist klein.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual Inference"
      ],
      "metadata": {
        "id": "kVJGF-A5urTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic imports\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
      ],
      "metadata": {
        "id": "b64zvm0FuiGi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic Model and tokenizer calling\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "5lWGZTcuvYsN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"translate English to German: The weather is nice.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "6fXpS94lvaUu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"],\n",
        "    max_length=64,\n",
        "    num_beams=4, # like top_k or take more into considrration but instead of tokens it does seq of highest prob tokens\n",
        "    early_stopping=True #for cleaner and faster so it doenst hit the fan or limit and create half sense statements\n",
        ")\n"
      ],
      "metadata": {
        "id": "5fCQkXJABn6f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auWtLxbKEXpy",
        "outputId": "92686256-6502-4843-8206-5cfee79e21c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0,   644, 14845,   229,  9685,     5,     1]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "1wVIW0gDEZ4Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xzCCfVsE3ol",
        "outputId": "ec27b1da-a26e-4309-b793-439dc4c1899d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Das Wetter ist schön.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9w-co2yLE4Qb",
        "outputId": "2519a231-5d71-4441-b9c3-b982ba46560a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Das Wetter ist schön.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Trainer Training"
      ],
      "metadata": {
        "id": "653gK3DnE68V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        ")"
      ],
      "metadata": {
        "id": "t6RvALdxE5d7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Small toy dataset\n",
        "train_data = {\n",
        "    \"input\": [\n",
        "        \"translate English to German: The house is small.\",\n",
        "        \"summarize: The quick brown fox jumps over the lazy dog.\"\n",
        "    ],\n",
        "    \"target\": [\n",
        "        \"Das Haus ist klein.\",\n",
        "        \"A fox jumped over a dog.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "eval_data = {\n",
        "    \"input\": [\n",
        "        \"translate English to German: The cat sits on the mat.\"\n",
        "    ],\n",
        "    \"target\": [\n",
        "        \"Die Katze sitzt auf der Matte.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "datasets = DatasetDict({\n",
        "    \"train\": Dataset.from_dict(train_data),#Wraps your raw dictionary into a Hugging Face Dataset object.\n",
        "    \"eval\": Dataset.from_dict(eval_data)#Wraps your raw dictionary into a Hugging Face Dataset object.\n",
        "})"
      ],
      "metadata": {
        "id": "ipdk5p2SdMr3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load tokenizer & model\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "kL4BosCriMgq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Preprocessing function\n",
        "def preprocess(examples):\n",
        "    # 1. Tokenize input text (English or source sentence)\n",
        "    model_inputs = tokenizer(\n",
        "        examples[\"input\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=64\n",
        "    )\n",
        "\n",
        "    # 2. Tokenize target text (German or summary, etc.)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            examples[\"target\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=64\n",
        "        )\n",
        "\n",
        "    # 3. Replace padding tokens in labels with -100\n",
        "    model_inputs[\"labels\"] = [\n",
        "        [(t if t != tokenizer.pad_token_id else -100) for t in l]\n",
        "        for l in labels[\"input_ids\"]\n",
        "    ]\n",
        "\n",
        "    return model_inputs\n"
      ],
      "metadata": {
        "id": "XvQyhfB0iNwG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = datasets.map(preprocess, batched=True)\n",
        "tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "f1f7bf1dd95c4600a8712ac02dea9cdb",
            "5354a15a153d4b7c9ea850905dad9790",
            "4bbefdbf44214e4ca54e20cfd0461ea5",
            "8dc86cc0b8384f4d8ef1db3da9699be7",
            "6a5dcb8fbbaf499dba9ed1973766aeca",
            "5203e43537fe427f9460c72e344722d4",
            "121158dbc36048a498948df517c89faa",
            "797acf2185bb4d8fa2261723b5671243",
            "fbd5f6d04f524aa6b3feae08428cdd57",
            "59efa4655df6430bb933da90b4998389",
            "57f92509d33240c88ac791d05446aa8d",
            "cf9824c41e724db29985ac440b88ae70",
            "0913e64add8a4e97912083f9999366cd",
            "dc4a58bb8b544781bbc7ab0bb0f23c66",
            "1054d910d0084faf882ea614142e737c",
            "19d2fc56e2ad4cd8a9552a3d2d8e8489",
            "2c0bd96df16a4d618987df07932df636",
            "4d05ff69786f4963bffeae8ef73d7b3f",
            "8c8868ed20224fa2834493db87dcba10",
            "7b0aa4e915b84568801ea6dba04d9cbd",
            "cf7f7086a0f44ad18965beeb226b5c7a",
            "aa1f80641e7243eeb4e31a3f258400fd"
          ]
        },
        "id": "ZyyAOOG3t9cV",
        "outputId": "4c00f4dc-8db8-4468-f56e-7f0ae4dc5cfd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1f7bf1dd95c4600a8712ac02dea9cdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4007: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf9824c41e724db29985ac440b88ae70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2\n",
              "    })\n",
              "    eval: Dataset({\n",
              "        features: ['input', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = datasets.map(preprocess, batched=True, remove_columns=[\"input\", \"target\"])\n",
        "tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "eea5af9a6da5466d87cb9867fb409c3b",
            "cce5713e07504b248326ce1f34441b55",
            "16bdd9981d624ca097fec8513447f59b",
            "1e106c8bc9ee4292a138f9f831665329",
            "4636e943ae3f45a08ccef1c0aeff947e",
            "903ea6265c7943edb64922dce341fdc8",
            "c35499cca5514fe58aa09f6db1986312",
            "28f13370992b429389a129204cf5cea6",
            "ba3fdc20e1754970b30c6dec71ec3f0b",
            "d0df6aed6dd84dc3bbb0043f2f63547a",
            "8b6163f4af3244348e53bcca428a22f6",
            "5331046cac8146d49ec292298e4e3fe9",
            "85d09a604ab441cb80031a94f55e6701",
            "6d569dd33d4b461ebfcda12f278584a8",
            "d01610ec3aec4786ab17143c5228b3bf",
            "c9bfa35ca26741eb80de60fc894915a1",
            "508289d937004534abb7828d066c6274",
            "9420db51b59e4a24b5d79c97cc1686b0",
            "44602324c24f48a9b44f45ba20c9e2f4",
            "5657908f8c8a4922b6d40869f7ed302c",
            "4070eebbc76b41fa92730b81298c666f",
            "0bc83904f61a4f2f8a4868b2b061119a"
          ]
        },
        "id": "qEXYOxaOicoD",
        "outputId": "af9cfc89-9966-4fe8-e4a6-fdd130a81c4f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eea5af9a6da5466d87cb9867fb409c3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5331046cac8146d49ec292298e4e3fe9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2\n",
              "    })\n",
              "    eval: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model) #Padding tokens in labels must be set to ignore_index → so the model doesn’t compute loss on them\n",
        "#Shifted labels for decoder (Teacher Forcing)-Takes previous tokens as input.- Predicts the next token at each step."
      ],
      "metadata": {
        "id": "khJmW4I_uEON"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. TrainingArguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "dSRocvzmulvC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"eval\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GChqKeqKuuXi",
        "outputId": "a4244d4f-f4b2-4e53-8c5f-e83f00d1f6d2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4031814499.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "print(trainer.evaluate())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "lmkNzvq9uwQS",
        "outputId": "95f0cc8e-7075-4193-d3e2-bcd02b32fdb9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:04, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.187417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.18741720914840698, 'eval_runtime': 1.1461, 'eval_samples_per_second': 0.873, 'eval_steps_per_second': 0.873, 'epoch': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "trainer.save_model(\"./custom_Seq2Seq_model\")\n",
        "tokenizer.save_pretrained(\"./custom_Seq2Seq_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIqr5ERCnnrZ",
        "outputId": "b6cf3f3a-9004-4ab2-aee5-6c662817ca9c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./custom_Seq2Seq_model/tokenizer_config.json',\n",
              " './custom_Seq2Seq_model/special_tokens_map.json',\n",
              " './custom_Seq2Seq_model/spiece.model',\n",
              " './custom_Seq2Seq_model/added_tokens.json',\n",
              " './custom_Seq2Seq_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_code = ''"
      ],
      "metadata": {
        "id": "s_nLch_KnrjU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "016cb0b9f26945a1ba02e9f0b7729a5c",
            "3c35abf23edb41409ba9fad3790b979d",
            "0559cf2fbd7c44ab84b85206fa207c74",
            "f04e38b385d94296b060df0363c73b08",
            "ed2046fa45134832b57355ff3ca05307",
            "570cd40bf8d64bfe9793399b1d7b1130",
            "aa8edfd5bc6944adbec31c05ef813f95",
            "62b32034e25e450aa4e24f83fb7164ea",
            "ecd4501719f34399bc40014ab70f94e4",
            "f9347354a5594b99be4eb151ddfb240a",
            "6ed1528af8064e3f932ff36e6a571c36",
            "5f5f3d40332a4b85bdac23b294e5489e",
            "39798ba6ae954b08b73bb2498fac5be3",
            "eaf876ce29f74ed7af41d9409e9dc1ca",
            "5958a7506bf443438019a108b4ce62d1",
            "18f55e5ac81346908a21ee5e2c49ea41",
            "adcb4fe855fb4c5daffd400e9e5c54d1",
            "b06743963e3e447e968847297656e1e0",
            "38cdea0d255e4c669fbb7d66c10a934e",
            "287ffa2703be41d1bdc818b253268165"
          ]
        },
        "id": "ga1JI7xRntCi",
        "outputId": "3cfa3c7c-96ac-4653-8c86-d1e4a5fca0dc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "016cb0b9f26945a1ba02e9f0b7729a5c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = './custom_Seq2Seq_model'\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(name)\n",
        "\n",
        "# Push to Hub (your username/repo_name)\n",
        "repo_name = \"Noobhacker69/Custom_Seq2Seq_model\"  # you choose the name\n",
        "model.push_to_hub(repo_name)\n",
        "tokenizer.push_to_hub(repo_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "de155ce51d884617968329fbada4258e",
            "7a413340d9ee4a7a9731d1653cff064d",
            "896616b145964ff8b51560657bf643a6",
            "3fcf8b24298145b38a8c14bf993e4282",
            "ae7b5a1f34b447aa88f7c4abf42ae2d6",
            "ae8f95a6f5784500bd65c74d967456fb",
            "8ddf36a42b904a3babcdc729b2fec947",
            "b08833eb07ff4bdd95b59097e1e02f02",
            "963f3f80836e41b1a2865fd32b884509",
            "17b9860515e84a3bb43d87f52b66b32f",
            "a073b299603e48d2b56cbaf14a4ea6bb",
            "044335cc83e6455cab5a07046c653365",
            "6d914a20cabe4a60b5c9a0c764a214c2",
            "70f1c1d273234b608a0d4f68e1a263f4",
            "0c63f8e4f9254327be0d2305cc203f89",
            "0f7dd4b33dc34a34adac944b1d15ef6a",
            "90efe5c87dec4ea8b020fa02b29da578",
            "81069c03a32c47be99832f332b731a67",
            "5045904723f74d608113bb69b17fa0d1",
            "eaa935d9ef744bd88905d52dc9b7cd9a",
            "5ab00b5bd9444e64b07a41121ab203ed",
            "58f3bbc01afa4941bff18d21e723565f",
            "34085bd31b994a87bb7c2c9b87601539",
            "16bf8262cd1b4cb9a425a567015828f7",
            "476e849e760b49b9b93762f5497a2a82",
            "b9bb7e23a2794de6b9f8adff1dafc574",
            "84b79f08cfb3450e8a5a125637396f74",
            "213f29bb678d42f1aa79378e6a45936d",
            "089d2a85cf5e43678f55415758fa5e6b",
            "daf7570ffba44c948af1b3baab35d5e9",
            "7a4694ac4c27480e8a15bcb964b32d03",
            "166615d1432542db8ff6ff3ce95c66ef",
            "963ed697ba3c44a5868ed0dcad3bc347"
          ]
        },
        "id": "tjwiy7PlnukB",
        "outputId": "c5a4cccb-10ed-4384-ef3c-1ee3879b369e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de155ce51d884617968329fbada4258e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "044335cc83e6455cab5a07046c653365"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34085bd31b994a87bb7c2c9b87601539"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Noobhacker69/Custom_Seq2Seq_model/commit/110871d2601245f3847ef9a892039030507a206e', commit_message='Upload tokenizer', commit_description='', oid='110871d2601245f3847ef9a892039030507a206e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Noobhacker69/Custom_Seq2Seq_model', endpoint='https://huggingface.co', repo_type='model', repo_id='Noobhacker69/Custom_Seq2Seq_model'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "mname = 'Noobhacker69/Custom_Seq2Seq_model'\n",
        "tranli = pipeline(task=\"text2text-generation\",model=mname,tokenizer=mname)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Bj8j_Msncov",
        "outputId": "909b04f5-74c9-4427-89f4-70084a7dc026"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"translate English to Italian: The house is small.\""
      ],
      "metadata": {
        "id": "VtfnLFy_oNfJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = tranli(prompt)\n",
        "out[0]['generated_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S3_-xEfdCsG0",
        "outputId": "a36c154a-056b-47f2-a111-35be9bfcbfc4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Das Haus ist klein.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2F-WUvmTC3xm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}